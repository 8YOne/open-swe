version: "3.9"

services:
  langgraph:
    build:
      context: .
      dockerfile: Dockerfile.agent
    environment:
      - NODE_ENV=production
      - PORT=2024
      - OPEN_SWE_LOCAL_MODE=true
      - SECRETS_ENCRYPTION_KEY=${SECRETS_ENCRYPTION_KEY}
      - API_BEARER_TOKEN=${API_BEARER_TOKEN}
      # Point to Ollama running on the host or LAN; override via env as needed
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
    ports:
      - "2024:2024"

  web:
    build:
      context: .
      dockerfile: Dockerfile.web
    environment:
      - NODE_ENV=production
      - LANGGRAPH_API_URL=http://langgraph:2024
      - OPEN_SWE_LOCAL_MODE=true
      - SECRETS_ENCRYPTION_KEY=${SECRETS_ENCRYPTION_KEY}
      - API_BEARER_TOKEN=${API_BEARER_TOKEN}
      - NEXT_PUBLIC_API_URL=http://localhost:3000/api
    ports:
      - "3000:3000"
    depends_on:
      - langgraph



